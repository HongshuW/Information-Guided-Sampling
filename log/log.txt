2024-02-04 05:07:09,188:INFO:Elapsed time: 6745.104068040848 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length at most 5?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 100
Do we sample when decoding? True
Number of beams: 3
Repetition penalty: 0.5
max_new_tokens: 20
Top_p: 0.95
2024-02-04 06:59:25,816:INFO:Elapsed time: 6723.227125167847 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length at most 5?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 100
Do we sample when decoding? True
Number of beams: 3
Repetition penalty: 0.5
max_new_tokens: 20
Top_p: 0.95
2024-02-04 08:47:04,711:INFO:Elapsed time: 6445.445105791092 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length at most 5?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 100
Do we sample when decoding? True
Number of beams: 3
Repetition penalty: 0.5
max_new_tokens: 20
Top_p: 0.95
2024-02-04 10:33:09,376:INFO:Elapsed time: 6351.400695800781 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length at most 5?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 100
Do we sample when decoding? True
Number of beams: 3
Repetition penalty: 0.5
max_new_tokens: 20
Top_p: 0.95
2024-02-04 12:25:40,793:INFO:Elapsed time: 201.41714096069336 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length at most 5?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 3
Do we sample when decoding? True
Number of beams: 5
Repetition penalty: 1.0
max_new_tokens: 20
Top_p: 0.95
2024-02-04 12:31:10,250:INFO:Elapsed time: 145.90407919883728 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length ?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 3
Do we sample when decoding? True
Repetition penalty: 1.0
max_new_tokens: 20
Top_p: 0.95
Temperature: 1.1
All outputs:
{"10101": 0, "11000": 0, "11111": 0, "11110": 0, "11100": 0, "11011": 0, "10111": 0, "10001": 0, "11010": 0, "10100": 0, "10010": 0, "10110": 0, "10000": 0, "00000": 1, "10011": 0, "11001": 0, "11101": 0, "10000000000000000000": 2}
Classified outputs:
{"10101": 0, "11000": 0, "11111": 0, "11110": 0, "11100": 0, "11011": 0, "10111": 0, "10001": 0, "11010": 0, "10100": 0, "10010": 0, "10110": 0, "10000": 0, "00000": 1, "10011": 0, "11001": 0, "11101": 0, "other": 2}
Idea distribution:
{"10101": 0, "11000": 0, "11111": 0, "11110": 0, "11100": 0, "11011": 0, "10111": 0, "10001": 0, "11010": 0, "10100": 0, "10010": 0, "10110": 0, "10000": 0, "00000": 0, "10011": 0, "11001": 0, "11101": 0, "other": 0}
2024-02-04 16:32:24,542:INFO:Elapsed time: 14245.317054510117 seconds
Model: meta-llama/Llama-2-13b-hf
Prompt: Generate a random binary string of length 5?
Grammar: string_start_w_1_all_0.ebnf
Iterations: 200
Do we sample when decoding? True
Repetition penalty: 1.0
max_new_tokens: 20
Top_p: 0.95
Temperature: 1.1
All outputs:
{"11110": 0, "11001": 0, "10110": 0, "11000": 0, "11100": 0, "11010": 0, "11011": 0, "10010": 0, "00000": 48, "10100": 0, "10101": 0, "11111": 0, "10001": 0, "11101": 0, "10000": 0, "10011": 0, "10111": 0, "10000000000000000000": 113, "11001110001001101001": 1, "10111000011001000100": 1, "11010100111010010101": 1, "10100011101101110100": 1, "10110010000000001101": 1, "11110001101110110101": 1, "11": 3, "11101101101111111111": 1, "11001001101111010110": 1, "11010011100101111010": 1, "11010110100001011011": 1, "11001010010011110000": 1, "10101001010010001000": 1, "11010000110101000111": 1, "11000101111111101110": 1, "11010000110011101011": 1, "10110001010100011111": 1, "11011010011110100010": 1, "11000011011000000011": 1, "11011011001010111110": 1, "10110100011100000100": 1, "11000000000110011110": 1, "11101001001011011011": 1, "11111101001011111011": 1, "11111110111000000011": 1, "11110011100001010111": 1, "11001000001011001111": 1, "10100110001010010001": 1, "11001101111001000001": 1, "11111111111111101010": 1, "11000110001100100110": 1, "11101100101100111110": 1, "11001111001011111100": 1, "11110100101011011110": 1, "10110011000011100010": 1, "10110111100011010011": 1, "10110011101110010100": 1}
Classified outputs:
{"11110": 0, "11001": 0, "10110": 0, "11000": 0, "11100": 0, "11010": 0, "11011": 0, "10010": 0, "00000": 48, "10100": 0, "10101": 0, "11111": 0, "10001": 0, "11101": 0, "10000": 0, "10011": 0, "10111": 0, "other": 152}
Idea distribution:
{"11110": 12, "11001": 12, "10110": 12, "11000": 12, "11100": 12, "11010": 12, "11011": 12, "10010": 12, "00000": 12, "10100": 12, "10101": 12, "11111": 12, "10001": 12, "11101": 12, "10000": 12, "10011": 12, "10111": 12, "other": 0}
